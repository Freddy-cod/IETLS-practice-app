{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7113ba-0065-4482-bc7f-b82ff81c2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the relevant libraries\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import pyaudio\n",
    "import spacy\n",
    "from fpdf import FPDF\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0ef3f2-31f8-4c32-a030-5e3a963386dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio():\n",
    "    model_path = './extracted_files/vosk-model-small-en-us-0.15' \n",
    "    model = Model(model_path)\n",
    "    recognizer = KaldiRecognizer(model, 16000)\n",
    "    \n",
    "    # Set up microphone input\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)\n",
    "    stream.start_stream()\n",
    "\n",
    "    print(\"Start speaking... (press Ctrl+C to stop)\")\n",
    "    response_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(4000, exception_on_overflow=False)\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                # Transcription of the detected speech\n",
    "                result = recognizer.Result()\n",
    "                print(\"Transcribed:\", result)\n",
    "                text = json.loads(result)[\"text\"]\n",
    "                \n",
    "                # Collect the transcribed text for further use\n",
    "                response_text += \" \" + text\n",
    "                # If the speech is concluded, exit loop\n",
    "                if response_text.strip() != \"\":\n",
    "                    return response_text.strip()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping transcription...\")\n",
    "        return response_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adbb0011-f874-438a-a39d-76ab3c5b1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Neo Model\n",
    "model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # Automatically map layers to available GPUs/CPUs\n",
    "    torch_dtype=\"auto\",  # Automatically choose the appropriate precision\n",
    "    token=True,\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d7c0f4-d2be-4a3a-b0e3-e9ca8e1351fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(prompt):\n",
    "    \"\"\"\n",
    "    Generate IELTS-style questions using the LLaMA model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt for generating a question.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated question.\n",
    "    \"\"\"\n",
    "    # Ensure the tokenizer has a padding token\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n",
    "    \n",
    "    # Tokenize the input with attention mask\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True\n",
    "    ).to(\"cpu\")  # or .to(\"cpu\") if no GPU\n",
    "\n",
    "    # Generate the output with explicit pad_token_id\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        max_length=50,\n",
    "        num_beams=5,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text and return\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38dcd7ea-c634-47a9-8d12-b496ac1d3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_response(response):\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    doc = nlp(response)\n",
    "    grammar_errors = []\n",
    "    corrected_sentences = []\n",
    "    vocabulary_suggestions = []\n",
    "    pronunciation_tips = []\n",
    "    filler_words = [\"um\", \"uh\", \"like\", \"so\", \"you know\"]  # Example filler words for fluency analysis\n",
    "    filler_count = sum(response.lower().count(fw) for fw in filler_words)\n",
    "\n",
    "    # Grammar checks and corrections\n",
    "    for sent in doc.sents:\n",
    "        tokens = list(sent)\n",
    "        for token in tokens:\n",
    "            if token.dep_ == \"ROOT\" and token.tag_ not in [\"VBD\", \"VBG\", \"VBN\", \"VBZ\"]:  # Verb form check\n",
    "                grammar_errors.append(f\"Incorrect verb form: {token.text}\")\n",
    "        \n",
    "        # Generate a corrected sentence (simple example, improve with grammar models)\n",
    "        corrected_sentence = \" \".join([t.text if t.text not in grammar_errors else f\"({t.text})\" for t in tokens])\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "\n",
    "    # Lexical Resource: Vocabulary analysis and suggestions\n",
    "    token_counts = doc.count_by(spacy.attrs.LOWER)\n",
    "    overused_words = [doc.vocab[lower].text for lower, count in token_counts.items() if count > 2]\n",
    "    for word in overused_words:\n",
    "        vocabulary_suggestions.append(f\"Try using synonyms for '{word}'.\")\n",
    "\n",
    "    # Fluency and coherence scoring\n",
    "    coherence_score = len(list(doc.sents)) / (filler_count + 1)  # Simplified metric for coherence\n",
    "\n",
    "    # Pronunciation feedback placeholder (requires phoneme analysis)\n",
    "    pronunciation_tips.append(\"Practice clearer enunciation for better scoring.\")\n",
    "\n",
    "    # Word and grammar scores\n",
    "    word_count = len(doc)\n",
    "    fluency_score = max(0, 10 - filler_count)  # Example scoring metric\n",
    "    grammar_score = max(0, 10 - len(grammar_errors))\n",
    "\n",
    "    return {\n",
    "        \"grammar_errors\": grammar_errors,\n",
    "        \"corrected_sentences\": corrected_sentences,\n",
    "        \"vocabulary_suggestions\": vocabulary_suggestions,\n",
    "        \"pronunciation_tips\": pronunciation_tips,\n",
    "        \"word_count\": word_count,\n",
    "        \"fluency_score\": fluency_score,\n",
    "        \"coherence_score\": coherence_score,\n",
    "        \"grammar_score\": grammar_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ce0f078-c8f3-4f64-bc83-595272527ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(responses, analyses, filename=\"IELTS_Feedback.pdf\"):\n",
    "    # This function basically creates a pdf file based on the resuls generated above. \n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.cell(200, 10, txt=\"IELTS Speaking Test Feedback\", ln=True, align=\"C\")\n",
    "\n",
    "    # Assign based on a criteria\n",
    "    for i, (response, analysis) in enumerate(zip(responses, analyses)):\n",
    "        pdf.cell(200, 10, txt=f\"Part {i+1} Response: {response}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"Analysis:\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Word Count: {analysis['word_count']}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Fluency Score: {analysis['fluency_score']}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Coherence Score: {analysis['coherence_score']}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Grammar Score: {analysis['grammar_score']}\", ln=True)\n",
    "\n",
    "        if analysis[\"grammar_errors\"]:\n",
    "            pdf.cell(200, 10, txt=\"Grammar Errors:\", ln=True)\n",
    "            for error in analysis[\"grammar_errors\"]:\n",
    "                pdf.cell(200, 10, txt=f\"  * {error}\", ln=True)\n",
    "        if analysis[\"vocabulary_suggestions\"]:\n",
    "            pdf.cell(200, 10, txt=\"Vocabulary Suggestions:\", ln=True)\n",
    "            for suggestion in analysis[\"vocabulary_suggestions\"]:\n",
    "                pdf.cell(200, 10, txt=f\"  * {suggestion}\", ln=True)\n",
    "        if analysis[\"pronunciation_tips\"]:\n",
    "            pdf.cell(200, 10, txt=\"Pronunciation Tips:\", ln=True)\n",
    "            for tip in analysis[\"pronunciation_tips\"]:\n",
    "                pdf.cell(200, 10, txt=f\"  * {tip}\", ln=True)\n",
    "\n",
    "    pdf.output(filename)\n",
    "    print(f\"Report saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a9cc8e8-9395-4884-ace2-d7f67388eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mode():\n",
    "    print(\"You are now in Test Mode.\")\n",
    "    print(\"This is a full IELTS Speaking Test with 3 parts.\")\n",
    "\n",
    "    responses = []\n",
    "    analyses = []\n",
    "\n",
    "    # Part 1: Introduction\n",
    "    print(\"\\nPart 1: Introduction\")\n",
    "    question1 = ask_question('Ask a simply question')\n",
    "    print(\"Examiner:\", question1)\n",
    "    response1 = transcribe_audio()\n",
    "    print(\"Your response:\", response1)\n",
    "    analysis1 = analyze_response(response1)\n",
    "    responses.append(response1)\n",
    "    analyses.append(analysis1)\n",
    "\n",
    "    # Part 2: Long Turn (Cue Card Activity)\n",
    "    print(\"\\nPart 2: Long Turn (Cue Card Activity)\")\n",
    "    question2 = ask_question(\"Create another long question\")\n",
    "    print(\"Examiner:\", question2)\n",
    "    response2 = transcribe_audio()\n",
    "    print(\"Your response:\", response2)\n",
    "    analysis2 = analyze_response(response2)\n",
    "    responses.append(response2)\n",
    "    analyses.append(analysis2)\n",
    "\n",
    "    # Part 3: Two-Way Discussion\n",
    "    print(\"\\nPart 3: Two-Way Discussion\")\n",
    "    question3 = ask_question(\"Create an IELTS-style two-way discussion question.\")\n",
    "    print(\"Examiner:\", question3)\n",
    "    response3 = transcribe_audio()\n",
    "    print(\"Your response:\", response3)\n",
    "    analysis3 = analyze_response(response3)\n",
    "    responses.append(response3)\n",
    "    analyses.append(analysis3)\n",
    "\n",
    "    # Generate a comprehensive feedback report\n",
    "    generate_report(responses, analyses, filename=\"IELTS_Test_Feedback.pdf\")\n",
    "    print(\"Test complete. Feedback report saved as 'IELTS_Test_Feedback.pdf'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31b134d9-9576-4023-b829-cc154fa732ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now in Test Mode.\n",
      "This is a full IELTS Speaking Test with 3 parts.\n",
      "\n",
      "Part 1: Introduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examiner: Ask a simply question?\n",
      "\n",
      "A:\n",
      "\n",
      "If you want to know the answer to your question, you can use the following code:\n",
      "public static void main(String[] args) {\n",
      "    System.out.println(\"\n",
      "Start speaking... (press Ctrl+C to stop)\n",
      "Transcribed: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "Transcribed: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "Transcribed: {\n",
      "  \"text\" : \"i don't understand what you're saying\"\n",
      "}\n",
      "Your response: i don't understand what you're saying\n",
      "\n",
      "Part 2: Long Turn (Cue Card Activity)\n",
      "Examiner: Create another long question.\n",
      "\n",
      "A:\n",
      "\n",
      "You can do it like this:\n",
      "public static void main(String[] args) {\n",
      "    int i = 0;\n",
      "    int j = 0;\n",
      "  \n",
      "Start speaking... (press Ctrl+C to stop)\n",
      "Transcribed: {\n",
      "  \"text\" : \"okay\"\n",
      "}\n",
      "Your response: okay\n",
      "\n",
      "Part 3: Two-Way Discussion\n",
      "Examiner: Create an IELTS-style two-way discussion question.\n",
      "\n",
      "A:\n",
      "\n",
      "There are two ways to do this:\n",
      "\n",
      "Create an IELTS-style two-way discussion question.\n",
      "Create an IELTS-style\n",
      "Start speaking... (press Ctrl+C to stop)\n",
      "Transcribed: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "Transcribed: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "Transcribed: {\n",
      "  \"text\" : \"thank you\"\n",
      "}\n",
      "Your response: thank you\n",
      "Report saved as IELTS_Test_Feedback.pdf\n",
      "Test complete. Feedback report saved as 'IELTS_Test_Feedback.pdf'.\n"
     ]
    }
   ],
   "source": [
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    test_mode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
