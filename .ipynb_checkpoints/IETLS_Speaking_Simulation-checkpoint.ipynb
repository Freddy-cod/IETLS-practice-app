{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7113ba-0065-4482-bc7f-b82ff81c2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the relevant libraries\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import pyaudio\n",
    "import spacy\n",
    "from fpdf import FPDF\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0ef3f2-31f8-4c32-a030-5e3a963386dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio():\n",
    "    model_path = './extracted_files/vosk-model-small-en-us-0.15' \n",
    "    model = Model(model_path)\n",
    "    recognizer = KaldiRecognizer(model, 16000)\n",
    "    \n",
    "    # Set up microphone input\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)\n",
    "    stream.start_stream()\n",
    "\n",
    "    print(\"Start speaking... (press Ctrl+C to stop)\")\n",
    "    response_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(4000, exception_on_overflow=False)\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                # Transcription of the detected speech\n",
    "                result = recognizer.Result()\n",
    "                print(\"Transcribed:\", result)\n",
    "                text = json.loads(result)[\"text\"]\n",
    "                \n",
    "                # Collect the transcribed text for further use\n",
    "                response_text += \" \" + text\n",
    "                # If the speech is concluded, exit loop\n",
    "                if response_text.strip() != \"\":\n",
    "                    return response_text.strip()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping transcription...\")\n",
    "        return response_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc080b6-ac80-45ba-9d64-8320708d8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Falcon model and tokenizer\n",
    "# model_name = \"tiiuae/falcon-7b-instruct\"  # Change to \"tiiuae/falcon-40b-instruct\" for the larger model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=\"auto\",\n",
    "#     # Falcon models require this\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbb0011-f874-438a-a39d-76ab3c5b1d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a056accf544b49856cb92573e6d48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  68%|######7   | 357M/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alfre\\.cache\\huggingface\\hub\\models--EleutherAI--gpt-neo-125m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7692f7f6057f49ddb13203966509106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Replace this with the correct model name\n",
    "model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # Automatically map layers to available GPUs/CPUs\n",
    "    torch_dtype=\"auto\",  # Automatically choose the appropriate precision\n",
    "    token=True,\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d7c0f4-d2be-4a3a-b0e3-e9ca8e1351fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(prompt):\n",
    "    \"\"\"\n",
    "    Generate IELTS-style questions using the LLaMA model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt for generating a question.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated question.\n",
    "    \"\"\"\n",
    "    # Ensure the tokenizer has a padding token\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n",
    "    \n",
    "    # Tokenize the input with attention mask\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True\n",
    "    ).to(\"cpu\")  # or .to(\"cpu\") if no GPU\n",
    "\n",
    "    # Generate the output with explicit pad_token_id\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        max_length=50,\n",
    "        num_beams=5,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text and return\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fb335-c539-4203-a094-ac5d6e6a42d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38dcd7ea-c634-47a9-8d12-b496ac1d3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_response(response)\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    doc = nlp(response)\n",
    "    grammar_errors = []\n",
    "    corrected_sentences = []\n",
    "    vocabulary_suggestions = []\n",
    "    pronunciation_tips = []\n",
    "    filler_words = [\"um\", \"uh\", \"like\", \"so\", \"you know\"]  # Example filler words for fluency analysis\n",
    "    filler_count = sum(response.lower().count(fw) for fw in filler_words)\n",
    "\n",
    "    # Grammar checks and corrections\n",
    "    for sent in doc.sents:\n",
    "        tokens = list(sent)\n",
    "        for token in tokens:\n",
    "            if token.dep_ == \"ROOT\" and token.tag_ not in [\"VBD\", \"VBG\", \"VBN\", \"VBZ\"]:  # Verb form check\n",
    "                grammar_errors.append(f\"Incorrect verb form: {token.text}\")\n",
    "        \n",
    "        # Generate a corrected sentence (simple example, improve with grammar models)\n",
    "        corrected_sentence = \" \".join([t.text if t.text not in grammar_errors else f\"({t.text})\" for t in tokens])\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "\n",
    "    # Lexical Resource: Vocabulary analysis and suggestions\n",
    "    token_counts = doc.count_by(spacy.attrs.LOWER)\n",
    "    overused_words = [doc.vocab[lower].text for lower, count in token_counts.items() if count > 2]\n",
    "    for word in overused_words:\n",
    "        vocabulary_suggestions.append(f\"Try using synonyms for '{word}'.\")\n",
    "\n",
    "    # Fluency and coherence scoring\n",
    "    coherence_score = len(list(doc.sents)) / (filler_count + 1)  # Simplified metric for coherence\n",
    "\n",
    "    # Pronunciation feedback placeholder (requires phoneme analysis)\n",
    "    pronunciation_tips.append(\"Practice clearer enunciation for better scoring.\")\n",
    "\n",
    "    # Word and grammar scores\n",
    "    word_count = len(doc)\n",
    "    fluency_score = max(0, 10 - filler_count)  # Example scoring metric\n",
    "    grammar_score = max(0, 10 - len(grammar_errors))\n",
    "\n",
    "    return {\n",
    "        \"grammar_errors\": grammar_errors,\n",
    "        \"corrected_sentences\": corrected_sentences,\n",
    "        \"vocabulary_suggestions\": vocabulary_suggestions,\n",
    "        \"pronunciation_tips\": pronunciation_tips,\n",
    "        \"word_count\": word_count,\n",
    "        \"fluency_score\": fluency_score,\n",
    "        \"coherence_score\": coherence_score,\n",
    "        \"grammar_score\": grammar_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ce0f078-c8f3-4f64-bc83-595272527ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(responses, analyses, filename=\"IELTS_Feedback.pdf\"):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.cell(200, 10, txt=\"IELTS Speaking Test Feedback\", ln=True, align=\"C\")\n",
    "\n",
    "    for i, (response, analysis) in enumerate(zip(responses, analyses)):\n",
    "        pdf.cell(200, 10, txt=f\"Part {i+1} Response: {response}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"Analysis:\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Word Count: {analysis['word_count']}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Fluency Score: {analysis['fluency_score']}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Coherence Score: {analysis['coherence_score']}\", ln=True)\n",
    "        pdf.cell(200, 10, txt=f\"- Grammar Score: {analysis['grammar_score']}\", ln=True)\n",
    "\n",
    "        if analysis[\"grammar_errors\"]:\n",
    "            pdf.cell(200, 10, txt=\"Grammar Errors:\", ln=True)\n",
    "            for error in analysis[\"grammar_errors\"]:\n",
    "                pdf.cell(200, 10, txt=f\"  * {error}\", ln=True)\n",
    "        if analysis[\"vocabulary_suggestions\"]:\n",
    "            pdf.cell(200, 10, txt=\"Vocabulary Suggestions:\", ln=True)\n",
    "            for suggestion in analysis[\"vocabulary_suggestions\"]:\n",
    "                pdf.cell(200, 10, txt=f\"  * {suggestion}\", ln=True)\n",
    "        if analysis[\"pronunciation_tips\"]:\n",
    "            pdf.cell(200, 10, txt=\"Pronunciation Tips:\", ln=True)\n",
    "            for tip in analysis[\"pronunciation_tips\"]:\n",
    "                pdf.cell(200, 10, txt=f\"  * {tip}\", ln=True)\n",
    "\n",
    "    pdf.output(filename)\n",
    "    print(f\"Report saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9cc8e8-9395-4884-ace2-d7f67388eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mode():\n",
    "    print(\"You are now in Test Mode.\")\n",
    "    print(\"This is a full IELTS Speaking Test with 3 parts.\")\n",
    "\n",
    "    responses = []\n",
    "    analyses = []\n",
    "\n",
    "    # Part 1: Introduction\n",
    "    print(\"\\nPart 1: Introduction\")\n",
    "    question1 = ask_question(\"Create an IELTS-style introduction question.\")\n",
    "    print(\"Examiner:\", question1)\n",
    "    response1 = transcribe_audio()\n",
    "    print(\"Your response:\", response1)\n",
    "    analysis1 = analyze_response(response1)\n",
    "    responses.append(response1)\n",
    "    analyses.append(analysis1)\n",
    "\n",
    "    # Part 2: Long Turn (Cue Card Activity)\n",
    "    print(\"\\nPart 2: Long Turn (Cue Card Activity)\")\n",
    "    question2 = ask_question(\"Create an IELTS-style cue card question.\")\n",
    "    print(\"Examiner:\", question2)\n",
    "    response2 = transcribe_audio()\n",
    "    print(\"Your response:\", response2)\n",
    "    analysis2 = analyze_response(response2)\n",
    "    responses.append(response2)\n",
    "    analyses.append(analysis2)\n",
    "\n",
    "    # Part 3: Two-Way Discussion\n",
    "    print(\"\\nPart 3: Two-Way Discussion\")\n",
    "    question3 = ask_question(\"Create an IELTS-style two-way discussion question.\")\n",
    "    print(\"Examiner:\", question3)\n",
    "    response3 = transcribe_audio()\n",
    "    print(\"Your response:\", response3)\n",
    "    analysis3 = analyze_response(response3)\n",
    "    responses.append(response3)\n",
    "    analyses.append(analysis3)\n",
    "\n",
    "    # Generate a comprehensive feedback report\n",
    "    generate_report(responses, analyses, filename=\"IELTS_Test_Feedback.pdf\")\n",
    "    print(\"Test complete. Feedback report saved as 'IELTS_Test_Feedback.pdf'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31b134d9-9576-4023-b829-cc154fa732ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now in Test Mode.\n",
      "This is a full IELTS Speaking Test with 3 parts.\n",
      "\n",
      "Part 1: Introduction\n",
      "Examiner: Create an IELTS-style introduction question.\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Introduction\n",
      "\n",
      "Start speaking... (press Ctrl+C to stop)\n",
      "Transcribed: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "Transcribed: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "Your response: hello\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the program\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtest_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mtest_mode\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m response1 \u001b[38;5;241m=\u001b[39m transcribe_audio()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response1)\n\u001b[1;32m---> 14\u001b[0m analysis1 \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m responses\u001b[38;5;241m.\u001b[39mappend(response1)\n\u001b[0;32m     16\u001b[0m analyses\u001b[38;5;241m.\u001b[39mappend(analysis1)\n",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m, in \u001b[0;36manalyze_response\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_response\u001b[39m(response):\n\u001b[1;32m----> 2\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m(response)\n\u001b[0;32m      3\u001b[0m     grammar_errors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m     corrected_sentences \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    test_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771989ef-789c-4c7c-b0c8-7b06e87b9caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
